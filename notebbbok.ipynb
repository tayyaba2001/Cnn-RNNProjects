{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "Po97ujSxjcvv",
        "outputId": "4360205a-0df6-4483-ca65-ce5cce243c4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_separable_conv2d_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m286\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseSeparableConv2D\u001b[0m)           │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_separable_conv2d_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseSeparableConv2D</span>)           │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m286\u001b[0m (1.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> (1.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286\u001b[0m (1.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286</span> (1.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow.keras as keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, DepthwiseConv2D, Conv2D\n",
        "from keras.models import Model\n",
        "\n",
        "# Load dataset\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "# Define the Depthwise Separable Convolution Layer\n",
        "class DepthwiseSeparableConv2D(keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, padding, activation):\n",
        "        super(DepthwiseSeparableConv2D, self).__init__()\n",
        "        # Depthwise convolution\n",
        "        self.depthwise = DepthwiseConv2D(kernel_size=kernel_size, padding=padding, activation=activation)\n",
        "        # Pointwise convolution\n",
        "        self.pointwise = Conv2D(filters=filters, kernel_size=(1, 1), activation=activation)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        # Apply depthwise convolution first, followed by pointwise convolution\n",
        "        x = self.depthwise(input_tensor)\n",
        "        return self.pointwise(x)\n",
        "\n",
        "# Constructing a model using the Depthwise Separable Convolution Layer\n",
        "visible = Input(shape=(32, 32, 3))  # CIFAR-10 images have size 32x32 with 3 color channels (RGB)\n",
        "depthwise_separable = DepthwiseSeparableConv2D(filters=64, kernel_size=(3,3), padding=\"valid\", activation=\"relu\")(visible)\n",
        "depthwise_model = Model(inputs=visible, outputs=depthwise_separable)\n",
        "\n",
        "# Print model summary to see the number of parameters\n",
        "depthwise_model.summary()\n",
        "\n",
        "# Comparison with a similar model using a regular Conv2D layer\n",
        "normal = Conv2D(filters=64, kernel_size=(3,3), padding=\"valid\", activation=\"relu\")(visible)\n",
        "normal_model = Model(inputs=visible, outputs=normal)\n",
        "\n",
        "# Print model summary of the normal Conv2D model\n",
        "normal_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, SeparableConv2D\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "# Normalize data to range [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "# VGG block with standard convolutional layers\n",
        "def vgg_block(layer_in, n_filters, n_conv):\n",
        "    for _ in range(n_conv):\n",
        "        layer_in = Conv2D(filters=n_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(layer_in)\n",
        "    layer_in = MaxPooling2D((2, 2), strides=(2, 2))(layer_in)\n",
        "    return layer_in\n",
        "\n",
        "# VGG block with depthwise separable convolutional layers\n",
        "def vgg_depthwise_block(layer_in, n_filters, n_conv):\n",
        "    for _ in range(n_conv):\n",
        "        layer_in = SeparableConv2D(filters=n_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(layer_in)\n",
        "    layer_in = MaxPooling2D((2, 2), strides=(2, 2))(layer_in)\n",
        "    return layer_in\n",
        "\n",
        "# Model with standard convolutional layers\n",
        "def create_standard_vgg():\n",
        "    visible = Input(shape=(32, 32, 3))\n",
        "    layer = vgg_block(visible, 64, 2)\n",
        "    layer = vgg_block(layer, 128, 2)\n",
        "    layer = vgg_block(layer, 256, 2)\n",
        "    layer = Flatten()(layer)\n",
        "    output = Dense(units=10, activation=\"softmax\")(layer)\n",
        "    model = Model(inputs=visible, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Model with depthwise separable convolutional layers\n",
        "def create_depthwise_vgg():\n",
        "    visible = Input(shape=(32, 32, 3))\n",
        "    layer = vgg_depthwise_block(visible, 64, 2)\n",
        "    layer = vgg_depthwise_block(layer, 128, 2)\n",
        "    layer = vgg_depthwise_block(layer, 256, 2)\n",
        "    layer = Flatten()(layer)\n",
        "    output = Dense(units=10, activation=\"softmax\")(layer)\n",
        "    model = Model(inputs=visible, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Create and compile standard VGG model\n",
        "standard_vgg = create_standard_vgg()\n",
        "standard_vgg.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
        "\n",
        "# Train standard VGG model\n",
        "print(\"Training standard VGG model...\")\n",
        "history_standard = standard_vgg.fit(trainX, trainY, batch_size=128, epochs=10, validation_data=(testX, testY))\n",
        "\n",
        "# Evaluate standard VGG model\n",
        "print(\"\\nEvaluating standard VGG model...\")\n",
        "standard_loss, standard_acc = standard_vgg.evaluate(testX, testY)\n",
        "print(f\"Standard VGG Model Accuracy: {standard_acc:.4f}\")\n",
        "\n",
        "# Create and compile depthwise separable VGG model\n",
        "depthwise_vgg = create_depthwise_vgg()\n",
        "depthwise_vgg.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
        "\n",
        "# Train depthwise separable VGG model\n",
        "print(\"\\nTraining depthwise separable VGG model...\")\n",
        "history_depthwise = depthwise_vgg.fit(trainX, trainY, batch_size=128, epochs=10, validation_data=(testX, testY))\n",
        "\n",
        "# Evaluate depthwise separable VGG model\n",
        "print(\"\\nEvaluating depthwise separable VGG model...\")\n",
        "depthwise_loss, depthwise_acc = depthwise_vgg.evaluate(testX, testY)\n",
        "print(f\"Depthwise Separable VGG Model Accuracy: {depthwise_acc:.4f}\")\n",
        "\n",
        "# Compare model parameter counts\n",
        "print(\"\\nModel Summary - Standard VGG:\")\n",
        "standard_vgg.summary()\n",
        "\n",
        "print(\"\\nModel Summary - Depthwise Separable VGG:\")\n",
        "depthwise_vgg.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeC_74VJxLYy",
        "outputId": "d53bf341-a11a-4fee-c296-2d7d7ac7f685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training standard VGG model...\n",
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1208s\u001b[0m 3s/step - accuracy: 0.3288 - loss: 1.8092 - val_accuracy: 0.6159 - val_loss: 1.0965\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1226s\u001b[0m 3s/step - accuracy: 0.6396 - loss: 1.0152 - val_accuracy: 0.7029 - val_loss: 0.8536\n",
            "Epoch 3/10\n",
            "\u001b[1m 98/391\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:57\u001b[0m 3s/step - accuracy: 0.7343 - loss: 0.7681"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# CIFAR-10 class names\n",
        "cifar10_classes = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "# Function to preprocess an uploaded image\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(32, 32))  # Resize to 32x32\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array.astype(\"float32\") / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to predict and display results\n",
        "def predict_image(model, image_path):\n",
        "    img_array = preprocess_image(image_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "    return cifar10_classes[predicted_class]\n",
        "\n",
        "# Upload images\n",
        "uploaded_files = files.upload()  # Use Colab to upload images\n",
        "\n",
        "# Test the uploaded images on both models\n",
        "for filename in uploaded_files:\n",
        "    print(f\"\\nTesting image: {filename}\")\n",
        "    image_path = filename\n",
        "    plt.imshow(load_img(image_path))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Predict using standard VGG model\n",
        "    result_standard = predict_image(standard_vgg, image_path)\n",
        "    print(f\"Standard VGG Model Prediction: {result_standard}\")\n",
        "\n",
        "    # Predict using depthwise separable VGG model\n",
        "    result_depthwise = predict_image(depthwise_vgg, image_path)\n",
        "    print(f\"Depthwise Separable VGG Model Prediction: {result_depthwise}\")\n"
      ],
      "metadata": {
        "id": "Y3XT53mnxvHy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}